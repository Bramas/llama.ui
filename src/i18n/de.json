{
  "header": {
    "title": {
      "noChat": "Neuer Chat",
      "settings": "Einstellungen"
    }
  },
  "chatScreen": {
    "welcome": "Hallo,",
    "welcomeNote": "wie kann ich dir helfen?"
  },
  "chatMessage": {
    "systemLabel": "System",
    "userLabel": "Du"
  },
  "settings": {
    "parameters": {
      "language": {
        "label": "Sprache",
        "note": "Benutzeroberfl√§che Anzeigesprache."
      },
      "provider": {
        "label": "Anbieter",
        "note": "Der Anbieter kann f√ºr die Verwendung in Rechnung gestellt werden."
      },
      "baseUrl": {
        "label": "Basis -URL",
        "note": "Stellen Sie die Basis -URL fest, wenn Sie den Standalone -Server verwenden."
      },
      "apiKey": {
        "label": "API -Schl√ºssel",
        "note": "Legen Sie die API-Taste fest, wenn Sie die Option-API-Key-Option f√ºr den Server verwenden."
      },
      "model": {
        "label": "Modell",
        "note": "Stellen Sie das Inferenzmodell ein."
      },
      "systemMessage": {
        "label": "Systemmeldung (wird deaktiviert, wenn sie leer gelassen wird)",
        "note": "Die Startnachricht, die definiert, wie sich das Modell verhalten sollte. Sie k√∂nnen Beispiele von <a class=\"underline\" href=\"https://prompts.chat/\" target=\"_blank\" rel=\"noopener noreferrer\">Awesome ChatGPT Prompts</a>"
      },
      "initials": {
        "label": "Benutzername",
        "note": ""
      },
      "pasteLongTextToFileLen": {
        "label": "Paste: Konvertieren Sie, wenn L√§nge>",
        "note": "Beim Einf√ºgen eines langen Textes wird er in eine Datei konvertiert. Sie k√∂nnen die Dateil√§nge steuern, indem Sie den Wert dieses Parameters festlegen. Auf 0 einstellen, um zu deaktivieren."
      },
      "pdfAsImage": {
        "label": "Verwenden Sie PDF als Bild anstelle von Text",
        "note": "F√ºgen Sie das PDF als Bild anstelle von Text bei. Nur mit multimodalen Modellen mit Visionsunterst√ºtzung unterst√ºtzt."
      },
      "showTokensPerSecond": {
        "label": "Performance -Metriken zeigen",
        "note": "Aktivieren Sie, um die Verarbeitungsgeschwindigkeit, die Zeiten usw. zu sehen."
      },
      "showThoughtInProgress": {
        "label": "Erweitern Sie den Denkabschnitt",
        "note": "Erweitern Sie die Denknachricht beim Generieren von Nachrichten"
      },
      "excludeThoughtOnReq": {
        "label": "Denknachrichten zum Senden ausschlie√üen",
        "note": "Denknachrichten ausschlie√üen, wenn Sie Anfragen an API senden (empfohlen)"
      },
      "overrideGenerationOptions": {
        "label": "√úberschreiben von Erzeugungsoptionen",
        "note": ""
      },
      "temperature": {
        "label": "",
        "note": "Steuert die Zuf√§lligkeit des generierten Textes, indem die Wahrscheinlichkeitsverteilung der Ausgangs -Token beeinflusst wird. H√∂her = zuf√§lliger, niedriger = fokussierter."
      },
      "top_k": {
        "label": "",
        "note": "H√§lt nur K -Top -Token."
      },
      "top_p": {
        "label": "",
        "note": "Grenzen Token f√ºr diejenigen, die zusammen eine kumulative Wahrscheinlichkeit von mindestens P haben"
      },
      "min_p": {
        "label": "",
        "note": "Begrenzt Token, die auf der Mindestwahrscheinlichkeit f√ºr ein Token beruhen, im Vergleich zur Wahrscheinlichkeit des wahrscheinlichsten Tokens."
      },
      "max_tokens": {
        "label": "",
        "note": "Die maximale Anzahl von Token pro Ausgang."
      },
      "overrideSamplersOptions": {
        "label": "Ersetzen Sie die Optionen der Samplers",
        "note": ""
      },
      "samplers": {
        "label": "Sampler -Warteschlange",
        "note": "Die Reihenfolge, in der Probenehmer auf vereinfachte Weise angewendet werden. Standard ist \"dkypmxt\": trocken-> top_k-> typ_p-> top_p-> min_p-> xtc-> temperatur"
      },
      "dynatemp_range": {
        "label": "",
        "note": "Addon f√ºr den Temperaturabtaster. Der Mehrwert f√ºr den Bereich der dynamischen Temperatur, der die Wahrscheinlichkeiten durch Entropie von Token anpasst."
      },
      "dynatemp_exponent": {
        "label": "",
        "note": "Addon f√ºr den Temperaturabtaster. Gl√§ttet die Wahrscheinlichkeitsumverteilung auf der Grundlage des wahrscheinlichsten Tokens."
      },
      "typical_p": {
        "label": "",
        "note": "Sortiert und begrenzt Token basierend auf dem Unterschied zwischen Protokollverbesserbarkeit und Entropie."
      },
      "xtc_probability": {
        "label": "",
        "note": "XTC Sampler schneidet Top -Token aus; Dieser Parameter steuert die Wahrscheinlichkeit, Token √ºberhaupt zu schneiden. 0 deaktiviert XTC."
      },
      "xtc_threshold": {
        "label": "",
        "note": "XTC Sampler schneidet Top -Token aus; Dieser Parameter steuert die Token -Wahrscheinlichkeit, die erforderlich ist, um dieses Token zu schneiden."
      },
      "overridePenaltyOptions": {
        "label": "Strafe ersetzen",
        "note": ""
      },
      "repeat_last_n": {
        "label": "",
        "note": "Letzte N -Token, die f√ºr die Bestrafung der Wiederholung in Betracht gezogen werden sollten"
      },
      "repeat_penalty": {
        "label": "",
        "note": "Steuert die Wiederholung von Token -Sequenzen im generierten Text"
      },
      "presence_penalty": {
        "label": "",
        "note": "Begrenzt die Token basierend darauf, ob sie in der Ausgabe erscheinen oder nicht."
      },
      "frequency_penalty": {
        "label": "",
        "note": "Begrenzt die Token basierend darauf, wie oft sie in der Ausgabe erscheinen."
      },
      "dry_multiplier": {
        "label": "",
        "note": "Trockene Probenahme reduziert die Wiederholung im erzeugten Text auch in langen Kontexten. Dieser Parameter legt den Multiplikator f√ºr trockene Probenahme fest."
      },
      "dry_base": {
        "label": "",
        "note": "Trockene Probenahme reduziert die Wiederholung im erzeugten Text auch in langen Kontexten. Dieser Parameter legt den Basiswert der trockenen Probenahme fest."
      },
      "dry_allowed_length": {
        "label": "",
        "note": "Trockene Probenahme reduziert die Wiederholung im erzeugten Text auch in langen Kontexten. Dieser Parameter legt die zul√§ssige L√§nge f√ºr trockene Probenahme fest."
      },
      "dry_penalty_last_n": {
        "label": "",
        "note": "Trockene Probenahme reduziert die Wiederholung im erzeugten Text auch in langen Kontexten. Dieser Parameter setzt Trockenstrafe f√ºr die letzten N -Token."
      },
      "custom": {
        "label": "Benutzerdefinierte JSON -Konfiguration",
        "note": "Weitere Informationen finden Sie unter <a class=\"underline\" href=\"https://github.com/ggerganov/llama.cpp/blob/master/tools/server/README.md\" target=\"_blank\" rel=\"noopener noreferrer\"> Serverdokumentation </a>"
      },
      "pyIntepreterEnabled": {
        "label": "Aktivieren Sie den Python -Dolmetscher",
        "note": "Diese Funktion verwendet <a class=\"underline\" href=\"https://pyodide.org\" target=\"_blank\" rel=\"noopener noreferrer\">pyodide</a>, heruntergeladen von CDN. Um diese Funktion zu verwenden, bitten Sie die LLM, Python -Code in einem Markdown -Code -Block zu generieren. Auf dem Codeblock sehen Sie eine Schaltfl√§che \"Ausf√ºhren\" in der N√§he der Schaltfl√§che \"Kopieren\"."
      },
      "ttsPitch": {
        "label": "Tonh√∂he",
        "note": "Die Tonh√∂he, auf der die √Ñu√üerung gesprochen wird."
      },
      "ttsRate": {
        "label": "Rate",
        "note": "Die Geschwindigkeit, mit der die √Ñu√üerung gesprochen wird."
      },
      "ttsVoice": {
        "label": "Stimme",
        "note": "Die Stimme, die verwendet wird, um die √Ñu√üerung zu sprechen."
      },
      "ttsVolume": {
        "label": "Volumen",
        "note": "Der Band, in dem die √Ñu√üerung gesprochen wird."
      }
    },
    "textToSpeech": {
      "check": {
        "label": "√úberpr√ºfen",
        "text": "Hallo Welt!"
      }
    },
    "presetManager": {
      "newPreset": {
        "title": "Speichern Sie die aktuellen Einstellungen als Voreinstellung",
        "saveBtnLabel": "Neues Voreinsatz speichern"
      },
      "savedPresets": {
        "title": "Bestehende Voreinstellungen",
        "noPresetFound": "Noch keine Voreinstellungen."
      }
    },
    "themeManager": {
      "dataTheme": {
        "label": "Thema",
        "note": "W√§hlen Sie das Farbthema der Anwendung."
      },
      "syntaxTheme": {
        "label": "Syntaxthema",
        "note": "W√§hlen Sie das Farbthema f√ºr die Codebl√∂cke."
      }
    },
    "actionButtons": {
      "saveBtnLabel": "Speichern",
      "cancelBtnLabel": "Schlie√üen",
      "resetBtnLabel": "Zur√ºcksetzen"
    }
  },
  "toast": {
    "newVersion": {
      "icon": null,
      "title": "üéâ Neue Version verf√ºgbar",
      "description": "Update f√ºr die neuesten Funktionen und Korrekturen.",
      "note": "Ihre Gespr√§che werden gespeichert, aber vergessen Sie nicht, vor dem Update eine Sicherung zu erstellen.",
      "submitBtnLabel": "Aktualisieren",
      "cancelBtnLabel": "Sp√§ter"
    },
    "welcomePopup": {
      "icon": null,
      "title": "üëã Willkommen",
      "description": "Es sieht so aus, als h√§tten Sie die Modelle noch nicht eingerichtet. Gehen wir zu den Einstellungen, um Ihren Inferenzanbieter zu konfigurieren.",
      "note": "",
      "submitBtnLabel": "Einstellungen ge√∂ffnet",
      "cancelBtnLabel": "√úberspringen"
    },
    "noModelsPopup": {
      "icon": null,
      "title": "üòî Keine Modelle gefunden",
      "description": "Es sieht so aus, als h√§tten Sie die Modelle noch nicht eingerichtet, oder es gibt ein Problem mit Ihrem Anbieter. Gehen wir zu den Einstellungen, um zu √ºberpr√ºfen.",
      "note": "",
      "submitBtnLabel": "Einstellungen ge√∂ffnet",
      "cancelBtnLabel": "√úberspringen"
    }
  },
  "samplePrompts": [
    "Erz√§hlen Sie mir eine lustige Tatsache f√ºr heute.",
    "Sag mir einen Witz.",
    "Gib mir drei interessante wissenschaftliche Fakten.",
    "Listen Sie die Planeten in unserem Sonnensystem auf.",
    "Erkl√§ren Sie die Regeln des Schaches.",
    "Was sind einige gute Gespr√§chsstarter?",
    "Geben Sie 10 Geschenkideen f√ºr den besten Freund.",
    "Schreiben Sie eine Geburtstagsnachricht f√ºr meinen Freund.",
    "Schlagen Sie Themen f√ºr eine Geburtstagsfeier vor.",
    "Geben Sie mir Ideen f√ºr eine Spielabend.",
    "Geben Sie mir Ideen f√ºr einen Wochenendausflug.",
    "Tipps f√ºr meine erste Einzelreise.",
    "Erkl√§ren Sie einfach ein komplexes Konzept.",
    "Beheben Sie die Grammatik in diesem Text.",
    "Fassen Sie den folgenden Text zusammen.",
    "Schreiben Sie dies um, um formeller/ungezwungener zu sein.",
    "Hilf mir, eine professionelle E -Mail zu schreiben.",
    "Erstellen Sie einen Zeitplan f√ºr meinen Arbeitstag.",
    "Fassen Sie diese Besprechungsnotizen zusammen.",
    "Geben Sie mir Ideen f√ºr eine Teambuilding -Aktivit√§t."
  ]
}
